{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "!pip install imblearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCotHVRmuJAE",
        "outputId": "f25d3e5b-6a22-4823-cda6-fcaa55776844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2.post1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2.post1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (291.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.7/291.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.26.2.post1 xgboost-3.0.0\n",
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Collecting imbalanced-learn (from imblearn)\n",
            "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn->imblearn)\n",
            "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: sklearn-compat, imbalanced-learn, imblearn\n",
            "Successfully installed imbalanced-learn-0.13.0 imblearn-0.0 sklearn-compat-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILi0BpeBcmeT",
        "outputId": "a144eec6-458d-47d5-9fe9-a3a6a5a9435e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced dataset with realistic noise generated and saved to 'employee_training_data_large.csv'\n",
            "Dataset shape: (20000, 17)\n",
            "Class distribution: \n",
            "High_Performance\n",
            "1    0.6001\n",
            "0    0.3999\n",
            "Name: proportion, dtype: float64\n",
            "Columns: ['Employee_ID', 'Department', 'Training_Program', 'Pre_Training_Score', 'Post_Training_Score', 'Feedback', 'Engagement (hrs)', 'Sentiment_Score', 'Manager_Support_Rating', 'Learning_Style', 'Training_Difficulty', 'Trainer_Quality', 'Engagement_Support_Score', 'Score_Progress_Indicator', 'Training_Effectiveness', 'Motivation_Index', 'High_Performance']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define parameters\n",
        "n_samples = 20000\n",
        "class_ratio = 0.6  # 60% Class 1, 40% Class 0\n",
        "n_class_1 = int(n_samples * class_ratio)\n",
        "n_class_0 = n_samples - n_class_1\n",
        "\n",
        "# Initialize DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Employee_ID': range(1, n_samples + 1),\n",
        "    'High_Performance': np.concatenate([\n",
        "        np.ones(n_class_1, dtype=int),\n",
        "        np.zeros(n_class_0, dtype=int)\n",
        "    ])\n",
        "})\n",
        "\n",
        "# Shuffle High_Performance\n",
        "df['High_Performance'] = df['High_Performance'].sample(frac=1, random_state=42).values\n",
        "\n",
        "# Generate numerical features with increased overlap\n",
        "df['Post_Training_Score'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(84, 8, n_samples), 80, 100),\n",
        "    np.clip(np.random.normal(70, 10, n_samples), 50, 79)\n",
        ")\n",
        "\n",
        "df['Pre_Training_Score'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(70, 10, n_samples), 50, 90),\n",
        "    np.clip(np.random.normal(64, 10, n_samples), 40, 80)\n",
        ")\n",
        "\n",
        "df['Engagement (hrs)'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(13, 4, n_samples), 7, 20),\n",
        "    np.clip(np.random.normal(10, 4, n_samples), 5, 18)\n",
        ")\n",
        "\n",
        "df['Manager_Support_Rating'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(3.7, 0.8, n_samples), 2, 5),\n",
        "    np.clip(np.random.normal(3.0, 0.9, n_samples), 1, 4.8)\n",
        ")\n",
        "\n",
        "df['Sentiment_Score'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(0.7, 0.2, n_samples), 0.4, 1.0),\n",
        "    np.clip(np.random.normal(0.5, 0.25, n_samples), 0, 0.9)\n",
        ")\n",
        "\n",
        "# Add random noise to Sentiment_Score\n",
        "df['Sentiment_Score'] += np.random.normal(0, 0.05, n_samples)\n",
        "df['Sentiment_Score'] = np.clip(df['Sentiment_Score'], 0, 1)\n",
        "\n",
        "# Generate categorical features\n",
        "df['Feedback'] = np.where(df['Sentiment_Score'] >= 0.6, 'Positive', 'Negative')\n",
        "\n",
        "departments = ['IT', 'Sales', 'HR', 'Operations', 'Finance', 'Marketing']\n",
        "dept_probs = {\n",
        "    'IT': [0.65, 0.35],\n",
        "    'Sales': [0.6, 0.4],\n",
        "    'HR': [0.55, 0.45],\n",
        "    'Operations': [0.6, 0.4],\n",
        "    'Finance': [0.55, 0.45],\n",
        "    'Marketing': [0.6, 0.4]\n",
        "}\n",
        "df['Department'] = np.random.choice(departments, n_samples, p=[1/len(departments)]*len(departments))\n",
        "\n",
        "training_programs = ['Tech', 'Leadership', 'Sales', 'Operations', 'General']\n",
        "train_probs = {\n",
        "    'Tech': [0.7, 0.3],\n",
        "    'Leadership': [0.65, 0.35],\n",
        "    'Sales': [0.6, 0.4],\n",
        "    'Operations': [0.6, 0.4],\n",
        "    'General': [0.5, 0.5]\n",
        "}\n",
        "df['Training_Program'] = np.random.choice(training_programs, n_samples, p=[1/len(training_programs)]*len(training_programs))\n",
        "\n",
        "learning_styles = ['Visual', 'Auditory', 'Kinesthetic']\n",
        "learn_probs = {\n",
        "    'Visual': [0.6, 0.4],\n",
        "    'Auditory': [0.55, 0.45],\n",
        "    'Kinesthetic': [0.5, 0.5]\n",
        "}\n",
        "df['Learning_Style'] = np.random.choice(learning_styles, n_samples, p=[1/3, 1/3, 1/3])\n",
        "\n",
        "difficulties = ['Easy', 'Medium', 'Hard']\n",
        "diff_probs = {\n",
        "    'Easy': [0.7, 0.3],\n",
        "    'Medium': [0.55, 0.45],\n",
        "    'Hard': [0.45, 0.55]\n",
        "}\n",
        "df['Training_Difficulty'] = np.random.choice(difficulties, n_samples, p=[1/3, 1/3, 1/3])\n",
        "\n",
        "# Generate new columns with increased overlap\n",
        "df['Trainer_Quality'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(3.7, 0.8, n_samples), 2, 5),\n",
        "    np.clip(np.random.normal(3.0, 0.9, n_samples), 1, 4.8)\n",
        ")\n",
        "\n",
        "df['Engagement_Support_Score'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(45, 15, n_samples), 15, 80),\n",
        "    np.clip(np.random.normal(30, 12, n_samples), 5, 60)\n",
        ")\n",
        "\n",
        "df['Score_Progress_Indicator'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(0.4, 0.2, n_samples), 0.1, 0.8),\n",
        "    np.clip(np.random.normal(0.3, 0.2, n_samples), 0, 0.6)\n",
        ")\n",
        "\n",
        "df['Training_Effectiveness'] = np.where(\n",
        "    df['Training_Difficulty'] == 'Easy',\n",
        "    df['Trainer_Quality'] * 1.1,\n",
        "    np.where(\n",
        "        df['Training_Difficulty'] == 'Medium',\n",
        "        df['Trainer_Quality'] * 1.0,\n",
        "        df['Trainer_Quality'] * 0.9\n",
        "    )\n",
        ")\n",
        "df['Training_Effectiveness'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(3.8, 0.9, n_samples), 2, 5.5),\n",
        "    np.clip(np.random.normal(2.7, 1.0, n_samples), 1, 4.5)\n",
        ")\n",
        "\n",
        "df['Motivation_Index'] = df['Sentiment_Score'] * 5\n",
        "df['Motivation_Index'] += np.where(\n",
        "    df['Learning_Style'] == 'Visual', 0.3,\n",
        "    np.where(df['Learning_Style'] == 'Auditory', 0.1, 0.0)\n",
        ")\n",
        "df['Motivation_Index'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(3.6, 0.8, n_samples), 2, 5),\n",
        "    np.clip(np.random.normal(2.5, 1.0, n_samples), 0, 4.5)\n",
        ")\n",
        "\n",
        "# Add noise to Motivation_Index\n",
        "df['Motivation_Index'] += np.random.normal(0, 0.1, n_samples)\n",
        "df['Motivation_Index'] = np.clip(df['Motivation_Index'], 0, 5)\n",
        "\n",
        "# Adjust High_Performance based on categorical features\n",
        "for cat, probs in [(df['Department'], dept_probs), (df['Training_Program'], train_probs),\n",
        "                   (df['Learning_Style'], learn_probs), (df['Training_Difficulty'], diff_probs)]:\n",
        "    for value in probs.keys():\n",
        "        mask = cat == value\n",
        "        if mask.sum() > 0:\n",
        "            df.loc[mask, 'High_Performance'] = np.random.choice(\n",
        "                [1, 0], size=mask.sum(), p=probs[value]\n",
        "            )\n",
        "\n",
        "# Ensure class balance\n",
        "class_counts = df['High_Performance'].value_counts()\n",
        "if class_counts.get(1, 0) < n_class_1:\n",
        "    mask = (df['High_Performance'] == 0) & (np.random.rand(n_samples) < (n_class_1 - class_counts.get(1, 0)) / class_counts.get(0, n_samples))\n",
        "    df.loc[mask, 'High_Performance'] = 1\n",
        "elif class_counts.get(1, 0) > n_class_1:\n",
        "    mask = (df['High_Performance'] == 1) & (np.random.rand(n_samples) < (class_counts.get(1, 0) - n_class_1) / class_counts.get(1, 0))\n",
        "    df.loc[mask, 'High_Performance'] = 0\n",
        "\n",
        "# Recompute numerical features to align with final High_Performance\n",
        "df['Post_Training_Score'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(84, 8, n_samples), 80, 100),\n",
        "    np.clip(np.random.normal(70, 10, n_samples), 50, 79)\n",
        ")\n",
        "df['Pre_Training_Score'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(70, 10, n_samples), 50, 90),\n",
        "    np.clip(np.random.normal(64, 10, n_samples), 40, 80)\n",
        ")\n",
        "df['Engagement (hrs)'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(13, 4, n_samples), 7, 20),\n",
        "    np.clip(np.random.normal(10, 4, n_samples), 5, 18)\n",
        ")\n",
        "df['Manager_Support_Rating'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(3.7, 0.8, n_samples), 2, 5),\n",
        "    np.clip(np.random.normal(3.0, 0.9, n_samples), 1, 4.8)\n",
        ")\n",
        "df['Sentiment_Score'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(0.7, 0.2, n_samples), 0.4, 1.0),\n",
        "    np.clip(np.random.normal(0.5, 0.25, n_samples), 0, 0.9)\n",
        ")\n",
        "df['Feedback'] = np.where(df['Sentiment_Score'] >= 0.6, 'Positive', 'Negative')\n",
        "df['Trainer_Quality'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(3.7, 0.8, n_samples), 2, 5),\n",
        "    np.clip(np.random.normal(3.0, 0.9, n_samples), 1, 4.8)\n",
        ")\n",
        "df['Engagement_Support_Score'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(45, 15, n_samples), 15, 80),\n",
        "    np.clip(np.random.normal(30, 12, n_samples), 5, 60)\n",
        ")\n",
        "df['Score_Progress_Indicator'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(0.4, 0.2, n_samples), 0.1, 0.8),\n",
        "    np.clip(np.random.normal(0.3, 0.2, n_samples), 0, 0.6)\n",
        ")\n",
        "df['Training_Effectiveness'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(3.8, 0.9, n_samples), 2, 5.5),\n",
        "    np.clip(np.random.normal(2.7, 1.0, n_samples), 1, 4.5)\n",
        ")\n",
        "df['Motivation_Index'] = np.where(\n",
        "    df['High_Performance'] == 1,\n",
        "    np.clip(np.random.normal(3.6, 0.8, n_samples), 2, 5),\n",
        "    np.clip(np.random.normal(2.5, 1.0, n_samples), 0, 4.5)\n",
        ")\n",
        "\n",
        "# Reorder columns\n",
        "df = df[[\n",
        "    'Employee_ID', 'Department', 'Training_Program', 'Pre_Training_Score',\n",
        "    'Post_Training_Score', 'Feedback', 'Engagement (hrs)', 'Sentiment_Score',\n",
        "    'Manager_Support_Rating', 'Learning_Style', 'Training_Difficulty',\n",
        "    'Trainer_Quality', 'Engagement_Support_Score', 'Score_Progress_Indicator',\n",
        "    'Training_Effectiveness', 'Motivation_Index', 'High_Performance'\n",
        "]]\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('employee_training_data_large.csv', index=False)\n",
        "print(\"Balanced dataset with realistic noise generated and saved to 'employee_training_data_large.csv'\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Class distribution: \\n{df['High_Performance'].value_counts(normalize=True)}\")\n",
        "print(\"Columns:\", list(df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ceCUDD6y_Sd",
        "outputId": "2cce25aa-f683-4ee4-d208-13edf6f81643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Collecting patsy>=0.5.1 (from category_encoders)\n",
            "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.14.1)\n",
            "Collecting statsmodels>=0.9.0 (from category_encoders)\n",
            "  Downloading statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.9/232.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patsy, statsmodels, category_encoders\n",
            "Successfully installed category_encoders-2.8.1 patsy-1.0.1 statsmodels-0.14.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('employee_training_data_large.csv')\n",
        "\n",
        "# Define features\n",
        "features = [\n",
        "    'Department', 'Training_Program', 'Pre_Training_Score', 'Engagement (hrs)',\n",
        "    'Sentiment_Score', 'Manager_Support_Rating', 'Learning_Style',\n",
        "    'Training_Difficulty', 'Feedback', 'Trainer_Quality',\n",
        "    'Engagement_Support_Score', 'Score_Progress_Indicator',\n",
        "    'Training_Effectiveness', 'Motivation_Index'\n",
        "]\n",
        "categorical_cols = ['Department', 'Training_Program', 'Learning_Style', 'Training_Difficulty', 'Feedback']\n",
        "numerical_cols = [\n",
        "    'Pre_Training_Score', 'Engagement (hrs)', 'Sentiment_Score',\n",
        "    'Manager_Support_Rating', 'Trainer_Quality', 'Engagement_Support_Score',\n",
        "    'Score_Progress_Indicator', 'Training_Effectiveness', 'Motivation_Index'\n",
        "]\n",
        "\n",
        "# Define targets\n",
        "reg_target = 'Post_Training_Score'\n",
        "class_target = 'High_Performance'\n",
        "\n",
        "# Drop rows with missing values\n",
        "df = df.dropna(subset=features + [reg_target, class_target])\n",
        "\n",
        "# Split data\n",
        "X = df[features]\n",
        "y_reg = df[reg_target]\n",
        "y_class = df[class_target]\n",
        "X_train, X_test, y_reg_train, y_reg_test, y_class_train, y_class_test = train_test_split(\n",
        "    X, y_reg, y_class, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = Pipeline([\n",
        "    ('encoder', TargetEncoder(cols=categorical_cols)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Define regression models\n",
        "reg_models = {\n",
        "    'Linear Regression': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', LinearRegression())\n",
        "    ]),\n",
        "    'Random Forest Regressor': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ]),\n",
        "    'Gradient Boosting Regressor': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', GradientBoostingRegressor(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=5,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Define classification models\n",
        "class_models = {\n",
        "    'Logistic Regression': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', LogisticRegression(C=1.0, max_iter=1000, random_state=42))\n",
        "    ]),\n",
        "    'Random Forest Classifier': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ]),\n",
        "    'XGBoost Classifier': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            scale_pos_weight=1,\n",
        "            eval_metric='logloss',\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Train and evaluate regression models\n",
        "reg_results = []\n",
        "reg_feature_importances = []\n",
        "for name, model in reg_models.items():\n",
        "    model.fit(X_train, y_reg_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2 = r2_score(y_reg_test, y_pred)\n",
        "    mae = mean_absolute_error(y_reg_test, y_pred)\n",
        "    mse = mean_squared_error(y_reg_test, y_pred)\n",
        "    reg_results.append({\n",
        "        'Model': name,\n",
        "        'R2 Score': r2,\n",
        "        'MAE': mae,\n",
        "        'MSE': mse\n",
        "    })\n",
        "    if name in ['Random Forest Regressor', 'Gradient Boosting Regressor']:\n",
        "        importances = model.named_steps['regressor'].feature_importances_\n",
        "        for feature, importance in zip(features, importances):\n",
        "            reg_feature_importances.append({\n",
        "                'Model': name,\n",
        "                'Feature': feature,\n",
        "                'Importance': importance\n",
        "            })\n",
        "\n",
        "# Train and evaluate classification models\n",
        "class_results = []\n",
        "class_feature_importances = []\n",
        "for name, model in class_models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_class_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_class_test, y_pred)\n",
        "    if accuracy < 0.95:\n",
        "        print(f\"Warning: {name} accuracy ({accuracy:.4f}) is below 95%.\")\n",
        "    report = classification_report(y_class_test, y_pred, output_dict=True, zero_division=0)\n",
        "    class_results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision_0': report['0']['precision'],\n",
        "        'Recall_0': report['0']['recall'],\n",
        "        'F1_0': report['0']['f1-score'],\n",
        "        'Support_0': report['0']['support'],\n",
        "        'Precision_1': report['1']['precision'],\n",
        "        'Recall_1': report['1']['recall'],\n",
        "        'F1_1': report['1']['f1-score'],\n",
        "        'Support_1': report['1']['support']\n",
        "    })\n",
        "    if name in ['Random Forest Classifier', 'XGBoost Classifier']:\n",
        "        importances = model.named_steps['classifier'].feature_importances_\n",
        "        for feature, importance in zip(features, importances):\n",
        "            class_feature_importances.append({\n",
        "                'Model': name,\n",
        "                'Feature': feature,\n",
        "                'Importance': importance\n",
        "            })\n",
        "\n",
        "# Create results DataFrames\n",
        "reg_results_df = pd.DataFrame(reg_results)\n",
        "class_results_df = pd.DataFrame(class_results)\n",
        "reg_importances_df = pd.DataFrame(reg_feature_importances)\n",
        "class_importances_df = pd.DataFrame(class_feature_importances)\n",
        "\n",
        "# Save results to CSV\n",
        "output_df = pd.concat([\n",
        "    reg_results_df,\n",
        "    pd.DataFrame([{}]),\n",
        "    class_results_df,\n",
        "    pd.DataFrame([{}]),\n",
        "    reg_importances_df,\n",
        "    pd.DataFrame([{}]),\n",
        "    class_importances_df\n",
        "], ignore_index=True)\n",
        "output_df.to_csv('model_results.csv', index=False)\n",
        "\n",
        "# Print summary\n",
        "print(\"Regression Model Performance:\")\n",
        "print(reg_results_df.to_string(index=True))\n",
        "print(\"\\nClassification Model Performance:\")\n",
        "print(class_results_df.to_string(index=True))\n",
        "print(\"\\nResults and feature importances saved to 'model_results.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPKHg330y7G4",
        "outputId": "8308af1a-c100-4aea-9be3-d9f6cba26759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "Warning: Logistic Regression accuracy (0.9320) is below 95%.\n",
            "Training Random Forest Classifier...\n",
            "Training XGBoost Classifier...\n",
            "Regression Model Performance:\n",
            "                         Model  R2 Score       MAE        MSE\n",
            "0            Linear Regression  0.365745  6.331399  66.723147\n",
            "1      Random Forest Regressor  0.455646  5.922787  57.265536\n",
            "2  Gradient Boosting Regressor  0.473488  5.924666  55.388632\n",
            "\n",
            "Classification Model Performance:\n",
            "                      Model  Accuracy  Precision_0  Recall_0      F1_0  Support_0  Precision_1  Recall_1      F1_1  Support_1\n",
            "0       Logistic Regression   0.93200     0.921656  0.906642  0.914087     1596.0     0.938683  0.948835  0.943732     2404.0\n",
            "1  Random Forest Classifier   0.95825     0.982444  0.911654  0.945726     1596.0     0.944025  0.989185  0.966078     2404.0\n",
            "2        XGBoost Classifier   0.97325     0.980013  0.952381  0.965999     1596.0     0.968967  0.987105  0.977952     2404.0\n",
            "\n",
            "Results and feature importances saved to 'model_results.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define classification results from provided output\n",
        "class_data = {\n",
        "    'Model': ['Logistic Regression', 'Random Forest Classifier', 'XGBoost Classifier'],\n",
        "    'Accuracy': [0.93200, 0.95825, 0.97325],\n",
        "    'Precision_0': [0.921656, 0.982444, 0.980013],\n",
        "    'Recall_0': [0.906642, 0.911654, 0.952381],\n",
        "    'F1_0': [0.914087, 0.945726, 0.965999],\n",
        "    'Precision_1': [0.938683, 0.944025, 0.968967],\n",
        "    'Recall_1': [0.948835, 0.989185, 0.987105],\n",
        "    'F1_1': [0.943732, 0.966078, 0.977952],\n",
        "    'Support_0': [1596.0, 1596.0, 1596.0],\n",
        "    'Support_1': [2404.0, 2404.0, 2404.0]\n",
        "}\n",
        "class_df = pd.DataFrame(class_data)\n",
        "\n",
        "# Define regression results from provided output\n",
        "reg_data = {\n",
        "    'Model': ['Linear Regression', 'Random Forest Regressor', 'Gradient Boosting Regressor'],\n",
        "    'R2 Score': [0.365745, 0.455646, 0.473488],\n",
        "    'MAE': [6.331399, 5.922787, 5.924666],\n",
        "    'MSE': [66.723147, 57.265536, 55.388632]\n",
        "}\n",
        "reg_df = pd.DataFrame(reg_data)\n",
        "\n",
        "# Classification visualization\n",
        "metrics = ['Accuracy', 'Precision_0', 'Recall_0', 'F1_0', 'Precision_1', 'Recall_1', 'F1_1']\n",
        "models = class_df['Model']\n",
        "n_metrics = len(metrics)\n",
        "n_models = len(models)\n",
        "\n",
        "# Set up bar plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "bar_width = 0.25\n",
        "index = np.arange(n_metrics)\n",
        "\n",
        "# Plot bars for each model\n",
        "for i, model in enumerate(models):\n",
        "    scores = class_df.loc[class_df['Model'] == model, metrics].values.flatten()\n",
        "    ax.bar(index + i * bar_width, scores, bar_width, label=model)\n",
        "\n",
        "# Customize plot\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Classification Model Performance (Class 0: 1,596 samples, Class 1: 2,404 samples)')\n",
        "ax.set_xticks(index + bar_width * (n_models - 1) / 2)\n",
        "ax.set_xticklabels(metrics, rotation=45)\n",
        "ax.legend()\n",
        "ax.set_ylim(0.85, 1.0)  # Focus on high scores\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "plt.savefig('classification_metrics.png')\n",
        "plt.close()\n",
        "\n",
        "# Regression visualization\n",
        "reg_metrics = ['R2 Score', 'MAE', 'MSE']\n",
        "n_reg_metrics = len(reg_metrics)\n",
        "\n",
        "# Normalize MAE and MSE for visualization (scale to 0-1 for comparison)\n",
        "reg_df['MAE_scaled'] = 1 - (reg_df['MAE'] - reg_df['MAE'].min()) / (reg_df['MAE'].max() - reg_df['MAE'].min())\n",
        "reg_df['MSE_scaled'] = 1 - (reg_df['MSE'] - reg_df['MSE'].min()) / (reg_df['MSE'].max() - reg_df['MSE'].min())\n",
        "\n",
        "# Set up bar plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "index = np.arange(n_reg_metrics)\n",
        "\n",
        "# Plot bars for each model\n",
        "for i, model in enumerate(reg_df['Model']):\n",
        "    scores = reg_df.loc[reg_df['Model'] == model, ['R2 Score', 'MAE_scaled', 'MSE_scaled']].values.flatten()\n",
        "    ax.bar(index + i * bar_width, scores, bar_width, label=model)\n",
        "\n",
        "# Customize plot\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Normalized Score')\n",
        "ax.set_title('Regression Model Performance (R², Scaled MAE/MSE)')\n",
        "ax.set_xticks(index + bar_width * (n_models - 1) / 2)\n",
        "ax.set_xticklabels(['R² Score', 'MAE (scaled)', 'MSE (scaled)'])\n",
        "ax.legend()\n",
        "ax.set_ylim(0, 1.1)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "plt.savefig('regression_metrics.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"Visualizations saved as 'classification_metrics.png' and 'regression_metrics.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPGqJrCI3Crk",
        "outputId": "56e16fa6-34e1-4957-dd7f-5ea3a2f5ac60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualizations saved as 'classification_metrics.png' and 'regression_metrics.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaleido"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaneLdN23i8M",
        "outputId": "1161416d-218c-4cb7-ef76-a6ee6888e986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define classification results from provided output\n",
        "# Define the data from the provided results\n",
        "reg_data = {\n",
        "    'Model': ['Linear Regression', 'Random Forest Regressor', 'Gradient Boosting Regressor'],\n",
        "    'R2 Score': [0.949084, 0.989685, 0.997908],\n",
        "    'MAE': [1.707430, 0.664289, 0.349442],\n",
        "    'MSE': [5.356332, 1.085133, 0.220067]\n",
        "}\n",
        "class_data = {\n",
        "    'Model': ['Logistic Regression', 'Random Forest Classifier', 'XGBoost Classifier'],\n",
        "    'Accuracy': [0.97775, 0.96625, 0.99275],\n",
        "    'Precision_0': [0.975995, 0.994584, 0.995572],\n",
        "    'Recall_0': [0.968045, 0.920426, 0.986216],\n",
        "    'F1_0': [0.972004, 0.956069, 0.990872],\n",
        "    'Support_0': [1596.0, 1596.0, 1596.0],\n",
        "    'Precision_1': [0.978899, 0.949663, 0.990905],\n",
        "    'Recall_1': [0.984193, 0.996672, 0.997088],\n",
        "    'F1_1': [0.981539, 0.972600, 0.993987],\n",
        "    'Support_1': [2404.0, 2404.0, 2404.0]\n",
        "}\n",
        "reg_df = pd.DataFrame(reg_data)\n",
        "\n",
        "# Approximate confusion matrices based on recall and support\n",
        "# Logistic Regression: Class 0 errors ~149, Class 1 errors ~123\n",
        "# Random Forest: Class 0 errors ~141, Class 1 errors ~26\n",
        "# XGBoost: Class 0 errors ~76, Class 1 errors ~31\n",
        "cm_lr = np.array([[1447, 149], [123, 2281]])  # Logistic Regression\n",
        "cm_rf = np.array([[1455, 141], [26, 2378]])   # Random Forest\n",
        "cm_xgb = np.array([[1520, 76], [31, 2373]])   # XGBoost\n",
        "cms = {\n",
        "    'Logistic Regression': cm_lr,\n",
        "    'Random Forest Classifier': cm_rf,\n",
        "    'XGBoost Classifier': cm_xgb\n",
        "}\n",
        "\n",
        "# 1. Interactive Classification Bar Plot\n",
        "metrics = ['Accuracy', 'Precision_0', 'Recall_0', 'F1_0', 'Precision_1', 'Recall_1', 'F1_1']\n",
        "plot_data = class_df.melt(id_vars='Model', value_vars=metrics, var_name='Metric', value_name='Score')\n",
        "\n",
        "fig = px.bar(\n",
        "    plot_data,\n",
        "    x='Metric',\n",
        "    y='Score',\n",
        "    color='Model',\n",
        "    barmode='group',\n",
        "    title='Classification Model Performance (Class 0: 1,596, Class 1: 2,404)',\n",
        "    color_discrete_sequence=px.colors.sequential.Plasma,\n",
        "    height=600\n",
        ")\n",
        "fig.update_layout(\n",
        "    yaxis_range=[0.85, 1.0],\n",
        "    xaxis_title='Metrics',\n",
        "    yaxis_title='Score',\n",
        "    legend_title='Model',\n",
        "    template='plotly_dark'\n",
        ")\n",
        "fig.write_html('classification_metrics.html') # Now this should work\n",
        "fig.write_image('classification_metrics.png') # Using write_image instead of write_to_png for better compatibility\n",
        "\n",
        "# 2. Confusion Matrix Heatmaps\n",
        "fig = make_subplots(rows=1, cols=3, subplot_titles=list(cms.keys()), shared_yaxes=True)\n",
        "\n",
        "for i, (model, cm) in enumerate(cms.items(), 1):\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(\n",
        "            z=cm,\n",
        "            x=['Predicted 0', 'Predicted 1'],\n",
        "            y=['True 0', 'True 1'],\n",
        "            colorscale='Viridis',\n",
        "            showscale=(i == 3),\n",
        "            text=cm,\n",
        "            texttemplate='%{text}',\n",
        "            textfont=dict(size=12)\n",
        "        ),\n",
        "        row=1, col=i\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Confusion Matrices for Classification Models',\n",
        "    height=400,\n",
        "    width=1200,\n",
        "    template='plotly_dark'\n",
        ")\n",
        "fig.write_html('confusion_matrices.html')\n",
        "fig.write_image('confusion_matrices.png')\n",
        "\n",
        "# 3. Radar Chart for Classification Metrics\n",
        "fig = go.Figure()\n",
        "\n",
        "for model in class_df['Model']:\n",
        "    scores = class_df[class_df['Model'] == model][metrics].values.flatten()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=scores,\n",
        "        theta=metrics,\n",
        "        fill='toself',\n",
        "        name=model,\n",
        "        line=dict(width=2)\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    polar=dict(radialaxis=dict(range=[0.85, 1.0])),\n",
        "    showlegend=True,\n",
        "    title='Classification Models Comparison (Radar Chart)',\n",
        "    template='plotly_dark',\n",
        "    height=600\n",
        ")\n",
        "fig.write_html('radar_chart.html')\n",
        "fig.write_image('radar_chart.png')\n",
        "\n",
        "# 4. Interactive Regression Bar Plot\n",
        "# Normalize MAE and MSE for visualization\n",
        "reg_df['MAE_scaled'] = 1 - (reg_df['MAE'] - reg_df['MAE'].min()) / (reg_df['MAE'].max() - reg_df['MAE'].min())\n",
        "reg_df['MSE_scaled'] = 1 - (reg_df['MSE'] - reg_df['MSE'].min()) / (reg_df['MSE'].max() - reg_df['MSE'].min())\n",
        "\n",
        "reg_metrics = ['R2 Score', 'MAE_scaled', 'MSE_scaled']\n",
        "reg_plot_data = reg_df.melt(id_vars='Model', value_vars=reg_metrics, var_name='Metric', value_name='Score')\n",
        "\n",
        "fig = px.bar(\n",
        "    reg_plot_data,\n",
        "    x='Metric',\n",
        "    y='Score',\n",
        "    color='Model',\n",
        "    barmode='group',\n",
        "    title='Regression Model Performance (R², Scaled MAE/MSE)',\n",
        "    color_discrete_sequence=px.colors.sequential.Inferno,\n",
        "    height=600,\n",
        "    text_auto='.2f'\n",
        ")\n",
        "fig.update_layout(\n",
        "    yaxis_title='Normalized Score',\n",
        "    xaxis_title='Metrics',\n",
        "    legend_title='Model',\n",
        "    template='plotly_dark',\n",
        "    annotations=[\n",
        "        dict(\n",
        "            x=1, y=0.5, xref='x', yref='y',\n",
        "            text=f'Raw MAE: LR={reg_df[\"MAE\"][0]:.2f}, RF={reg_df[\"MAE\"][1]:.2f}, GB={reg_df[\"MAE\"][2]:.2f}',\n",
        "            showarrow=False,\n",
        "            font=dict(size=10)\n",
        "        ),\n",
        "        dict(\n",
        "            x=2, y=0.5, xref='x', yref='y',\n",
        "            text=f'Raw MSE: LR={reg_df[\"MSE\"][0]:.2f}, RF={reg_df[\"MSE\"][1]:.2f}, GB={reg_df[\"MSE\"][2]:.2f}',\n",
        "            showarrow=False,\n",
        "            font=dict(size=10)\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "fig.write_html('regression_metrics.html')\n",
        "fig.write_image('regression_metrics.png')\n",
        "\n",
        "# 5. Static Seaborn Plot (Fallback)\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.set_style('whitegrid')\n",
        "sns.barplot(\n",
        "    data=plot_data,\n",
        "    x='Metric',\n",
        "    y='Score',\n",
        "    hue='Model',\n",
        "    palette='viridis'\n",
        ")\n",
        "plt.title('Classification Model Performance (Static)', fontsize=14)\n",
        "plt.ylim(0.85, 1.0)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Model')\n",
        "plt.tight_layout()\n",
        "plt.savefig('classification_metrics_static.png')\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    data=reg_plot_data,\n",
        "    x='Metric',\n",
        "    y='Score',\n",
        "    hue='Model',\n",
        "    palette='magma'\n",
        ")\n",
        "plt.title('Regression Model Performance (Static, Scaled Metrics)', fontsize=14)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Model')\n",
        "plt.tight_layout()\n",
        "plt.savefig('regression_metrics_static.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"Interactive visualizations saved as HTML/PNG: 'classification_metrics', 'confusion_matrices', 'radar_chart', 'regression_metrics'\")\n",
        "print(\"Static visualizations saved as PNG: 'classification_metrics_static.png', 'regression_metrics_static.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27xGOfJ93UU4",
        "outputId": "9d30d76c-5cf2-44ce-f041-7f14655acdc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive visualizations saved as HTML/PNG: 'classification_metrics', 'confusion_matrices', 'radar_chart', 'regression_metrics'\n",
            "Static visualizations saved as PNG: 'classification_metrics_static.png', 'regression_metrics_static.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from category_encoders import TargetEncoder\n",
        "import uuid\n",
        "\n",
        "# Load dataset\n",
        "try:\n",
        "    df = pd.read_csv('employee_training_data_modified.csv')\n",
        "    print(f\"Loaded dataset with {len(df)} records.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'employee_training_data_modified.csv' not found.\")\n",
        "    exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Define features, including Improvement (%)\n",
        "features = [\n",
        "    'Department', 'Training_Program', 'Pre_Training_Score', 'Engagement (hrs)',\n",
        "    'Sentiment_Score', 'Manager_Support_Rating', 'Learning_Style',\n",
        "    'Training_Difficulty', 'Feedback', 'Trainer_Quality', # Changed from 'Trainer dottor_Quality'\n",
        "    'Engagement_Support_Score', 'Score_Progress_Indicator',\n",
        "    'Training_Effectiveness', 'Motivation_Index', 'Improvement (%)'\n",
        "]\n",
        "categorical_cols = ['Department', 'Training_Program', 'Learning_Style', 'Training_Difficulty', 'Feedback']\n",
        "numerical_cols = [\n",
        "    'Pre_Training_Score', 'Engagement (hrs)', 'Sentiment_Score',\n",
        "    'Manager_Support_Rating', 'Trainer_Quality', 'Engagement_Support_Score',\n",
        "    'Score_Progress_Indicator', 'Training_Effectiveness', 'Motivation_Index',\n",
        "    'Improvement (%)'\n",
        "]\n",
        "\n",
        "# Define targets\n",
        "reg_target = 'Post_Training_Score'\n",
        "class_target = 'High_Performance'\n",
        "\n",
        "# Verify all required columns are present\n",
        "missing_cols = [col for col in features + [reg_target, class_target] if col not in df.columns]\n",
        "if missing_cols:\n",
        "    print(f\"Error: Missing columns in dataset: {missing_cols}\")\n",
        "    exit(1)\n",
        "\n",
        "# Drop rows with missing values\n",
        "df = df.dropna(subset=features + [reg_target, class_target])\n",
        "print(f\"Dataset after dropping missing values: {len(df)} records.\")\n",
        "\n",
        "# Split data\n",
        "X = df[features]\n",
        "y_reg = df[reg_target]\n",
        "y_class = df[class_target]\n",
        "X_train, X_test, y_reg_train, y_reg_test, y_class_train, y_class_test = train_test_split(\n",
        "    X, y_reg, y_class, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = Pipeline([\n",
        "    ('encoder', TargetEncoder(cols=categorical_cols)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Define regression models\n",
        "reg_models = {\n",
        "    'Linear Regression': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', LinearRegression())\n",
        "    ]),\n",
        "    'Random Forest Regressor': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ]),\n",
        "    'Gradient Boosting Regressor': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', GradientBoostingRegressor(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=5,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Define classification models\n",
        "class_models = {\n",
        "    'Logistic Regression': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', LogisticRegression(C=1.0, max_iter=1000, random_state=42))\n",
        "    ]),\n",
        "    'Random Forest Classifier': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ]),\n",
        "    'XGBoost Classifier': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            scale_pos_weight=1,\n",
        "            eval_metric='logloss',\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Train and evaluate regression models\n",
        "reg_results = []\n",
        "reg_feature_importances = []\n",
        "for name, model in reg_models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    try:\n",
        "        model.fit(X_train, y_reg_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        r2 = r2_score(y_reg_test, y_pred)\n",
        "        mae = mean_absolute_error(y_reg_test, y_pred)\n",
        "        mse = mean_squared_error(y_reg_test, y_pred)\n",
        "        reg_results.append({\n",
        "            'Model': name,\n",
        "            'R2 Score': r2,\n",
        "            'MAE': mae,\n",
        "            'MSE': mse\n",
        "        })\n",
        "        if name in ['Random Forest Regressor', 'Gradient Boosting Regressor']:\n",
        "            importances = model.named_steps['regressor'].feature_importances_\n",
        "            for feature, importance in zip(features, importances):\n",
        "                reg_feature_importances.append({\n",
        "                    'Model': name,\n",
        "                    'Feature': feature,\n",
        "                    'Importance': importance\n",
        "                })\n",
        "    except Exception as e:\n",
        "        print(f\"Error training {name}: {e}\")\n",
        "\n",
        "# Train and evaluate classification models\n",
        "class_results = []\n",
        "class_feature_importances = []\n",
        "for name, model in class_models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    try:\n",
        "        model.fit(X_train, y_class_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_class_test, y_pred)\n",
        "        if accuracy < 0.95:\n",
        "            print(f\"Warning: {name} accuracy ({accuracy:.4f}) is below 95%.\")\n",
        "        report = classification_report(y_class_test, y_pred, output_dict=True, zero_division=0)\n",
        "        class_results.append({\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision_0': report['0']['precision'],\n",
        "            'Recall_0': report['0']['recall'],\n",
        "            'F1_0': report['0']['f1-score'],\n",
        "            'Support_0': report['0']['support'],\n",
        "            'Precision_1': report['1']['precision'],\n",
        "            'Recall_1': report['1']['recall'],\n",
        "            'F1_1': report['1']['f1-score'],\n",
        "            'Support_1': report['1']['support']\n",
        "        })\n",
        "        if name in ['Random Forest Classifier', 'XGBoost Classifier']:\n",
        "            importances = model.named_steps['classifier'].feature_importances_\n",
        "            for feature, importance in zip(features, importances):\n",
        "                class_feature_importances.append({\n",
        "                    'Model': name,\n",
        "                    'Feature': feature,\n",
        "                    'Importance': importance\n",
        "                })\n",
        "    except Exception as e:\n",
        "        print(f\"Error training {name}: {e}\")\n",
        "\n",
        "# Create results DataFrames\n",
        "reg_results_df = pd.DataFrame(reg_results)\n",
        "class_results_df = pd.DataFrame(class_results)\n",
        "reg_importances_df = pd.DataFrame(reg_feature_importances)\n",
        "class_importances_df = pd.DataFrame(class_feature_importances)\n",
        "\n",
        "# Save results to CSV\n",
        "try:\n",
        "    output_df = pd.concat([\n",
        "        reg_results_df,\n",
        "        pd.DataFrame([{}]),\n",
        "        class_results_df,\n",
        "        pd.DataFrame([{}]),\n",
        "        reg_importances_df,\n",
        "        pd.DataFrame([{}]),\n",
        "        class_importances_df\n",
        "    ], ignore_index=True)\n",
        "    output_df.to_csv('model_results_with_improvement.csv', index=False)\n",
        "    print(\"Results and feature importances saved to 'model_results_with_improvement.csv'\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving results: {e}\")\n",
        "\n",
        "# Print summary\n",
        "print(\"\\nRegression Model Performance:\")\n",
        "print(reg_results_df.to_string(index=True))\n",
        "print(\"\\nClassification Model Performance:\")\n",
        "print(class_results_df.to_string(index=True))\n"
      ],
      "metadata": {
        "id": "n8zwRx6a3CaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6f88d8-2205-4363-fbf6-a2fdaf9ac5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 20000 records.\n",
            "Dataset after dropping missing values: 20000 records.\n",
            "Training set size: 16000, Test set size: 4000\n",
            "Training Linear Regression...\n",
            "Training Random Forest Regressor...\n",
            "Training Gradient Boosting Regressor...\n",
            "Training Logistic Regression...\n",
            "Training Random Forest Classifier...\n",
            "Training XGBoost Classifier...\n",
            "Results and feature importances saved to 'model_results_with_improvement.csv'\n",
            "\n",
            "Regression Model Performance:\n",
            "                         Model  R2 Score       MAE       MSE\n",
            "0            Linear Regression  0.949084  1.707430  5.356332\n",
            "1      Random Forest Regressor  0.989685  0.664289  1.085133\n",
            "2  Gradient Boosting Regressor  0.997908  0.349442  0.220067\n",
            "\n",
            "Classification Model Performance:\n",
            "                      Model  Accuracy  Precision_0  Recall_0      F1_0  Support_0  Precision_1  Recall_1      F1_1  Support_1\n",
            "0       Logistic Regression   0.97775     0.975995  0.968045  0.972004     1596.0     0.978899  0.984193  0.981539     2404.0\n",
            "1  Random Forest Classifier   0.96625     0.994584  0.920426  0.956069     1596.0     0.949663  0.996672  0.972600     2404.0\n",
            "2        XGBoost Classifier   0.99275     0.995572  0.986216  0.990872     1596.0     0.990905  0.997088  0.993987     2404.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U kaleido"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wGDHHpi3rCP",
        "outputId": "7255b0ba-5ba7-4351-e614-a0b661d023c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the data from the provided results\n",
        "reg_data = {\n",
        "    'Model': ['Linear Regression', 'Random Forest Regressor', 'Gradient Boosting Regressor'],\n",
        "    'R2 Score': [0.949084, 0.989685, 0.997908],\n",
        "    'MAE': [1.707430, 0.664289, 0.349442],\n",
        "    'MSE': [5.356332, 1.085133, 0.220067]\n",
        "}\n",
        "class_data = {\n",
        "    'Model': ['Logistic Regression', 'Random Forest Classifier', 'XGBoost Classifier'],\n",
        "    'Accuracy': [0.97775, 0.96625, 0.99275],\n",
        "    'Precision_0': [0.975995, 0.994584, 0.995572],\n",
        "    'Recall_0': [0.968045, 0.920426, 0.986216],\n",
        "    'F1_0': [0.972004, 0.956069, 0.990872],\n",
        "    'Support_0': [1596.0, 1596.0, 1596.0],\n",
        "    'Precision_1': [0.978899, 0.949663, 0.990905],\n",
        "    'Recall_1': [0.984193, 0.996672, 0.997088],\n",
        "    'F1_1': [0.981539, 0.972600, 0.993987],\n",
        "    'Support_1': [2404.0, 2404.0, 2404.0]\n",
        "}\n",
        "\n",
        "reg_df = pd.DataFrame(reg_data)\n",
        "class_df = pd.DataFrame(class_data)\n",
        "\n",
        "# Set Seaborn style for better aesthetics\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
        "\n",
        "# --- Regression Visualizations ---\n",
        "\n",
        "# 1. Plotly Bar Plot for Regression Metrics (Saved as PNG)\n",
        "fig_reg = make_subplots(\n",
        "    rows=1, cols=3,\n",
        "    subplot_titles=(\"R² Score\", \"MAE\", \"MSE\"),\n",
        "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        ")\n",
        "\n",
        "fig_reg.add_trace(\n",
        "    go.Bar(x=reg_df['Model'], y=reg_df['R2 Score'], name=\"R² Score\", marker_color='rgb(55, 83, 109)'),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig_reg.add_trace(\n",
        "    go.Bar(x=reg_df['Model'], y=reg_df['MAE'], name=\"MAE\", marker_color='rgb(26, 118, 255)'),\n",
        "    row=1, col=2\n",
        ")\n",
        "fig_reg.add_trace(\n",
        "    go.Bar(x=reg_df['Model'], y=reg_df['MSE'], name=\"MSE\", marker_color='rgb(50, 171, 96)'),\n",
        "    row=1, col=3\n",
        ")\n",
        "\n",
        "fig_reg.update_layout(\n",
        "    title_text=\"Regression Model Performance Comparison\",\n",
        "    showlegend=False,\n",
        "    height=500,\n",
        "    width=1200,\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "fig_reg.update_yaxes(title_text=\"Score\", row=1, col=1)\n",
        "fig_reg.update_yaxes(title_text=\"Error\", row=1, col=2)\n",
        "fig_reg.update_yaxes(title_text=\"Error\", row=1, col=3)\n",
        "fig_reg.write_image(\"regression_bar_plot.png\", format=\"png\", scale=3)  # 300 DPI equivalent\n",
        "print(\"Saved regression bar plot to 'regression_bar_plot.png'\")\n",
        "\n",
        "# 2. Seaborn Heatmap for Regression Metrics\n",
        "plt.figure(figsize=(8, 6))\n",
        "reg_heatmap_data = reg_df.set_index('Model')[['R2 Score', 'MAE', 'MSE']]\n",
        "sns.heatmap(reg_heatmap_data, annot=True, cmap='coolwarm', fmt=\".4f\", linewidths=0.5)\n",
        "plt.title(\"Regression Metrics Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"regression_heatmap.png\", dpi=300)\n",
        "plt.close()\n",
        "print(\"Saved regression heatmap to 'regression_heatmap.png'\")\n",
        "\n",
        "# --- Classification Visualizations ---\n",
        "\n",
        "# 1. Plotly Grouped Bar Plot for Classification Metrics (Saved as PNG)\n",
        "fig_class = go.Figure()\n",
        "metrics = ['Accuracy', 'Precision_0', 'Recall_0', 'F1_0', 'Precision_1', 'Recall_1', 'F1_1']\n",
        "colors = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692']\n",
        "\n",
        "for metric, color in zip(metrics, colors):\n",
        "    fig_class.add_trace(\n",
        "        go.Bar(\n",
        "            x=class_df['Model'],\n",
        "            y=class_df[metric],\n",
        "            name=metric,\n",
        "            marker_color=color\n",
        "        )\n",
        "    )\n",
        "\n",
        "fig_class.update_layout(\n",
        "    title_text=\"Classification Model Performance Comparison\",\n",
        "    barmode='group',\n",
        "    height=600,\n",
        "    width=1200,\n",
        "    template=\"plotly_white\",\n",
        "    yaxis_title=\"Score\",\n",
        "    legend_title=\"Metrics\",\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"center\", x=0.5)\n",
        ")\n",
        "fig_class.write_image(\"classification_bar_plot.png\", format=\"png\", scale=3)  # 300 DPI equivalent\n",
        "print(\"Saved classification bar plot to 'classification_bar_plot.png'\")\n",
        "\n",
        "# 2. Plotly Radar Chart for Classification Metrics (Saved as PNG)\n",
        "fig_radar = go.Figure()\n",
        "\n",
        "for _, row in class_df.iterrows():\n",
        "    fig_radar.add_trace(\n",
        "        go.Scatterpolar(\n",
        "            r=[row['Accuracy'], row['Precision_0'], row['Recall_0'], row['F1_0'],\n",
        "               row['Precision_1'], row['Recall_1'], row['F1_1']],\n",
        "            theta=['Accuracy', 'Precision (0)', 'Recall (0)', 'F1 (0)',\n",
        "                   'Precision (1)', 'Recall (1)', 'F1 (1)'],\n",
        "            fill='toself',\n",
        "            name=row['Model']\n",
        "        )\n",
        "    )\n",
        "\n",
        "fig_radar.update_layout(\n",
        "    title_text=\"Classification Model Performance (Radar Chart)\",\n",
        "    polar=dict(radialaxis=dict(visible=True, range=[0.9, 1.0])),\n",
        "    showlegend=True,\n",
        "    height=600,\n",
        "    width=800,\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "fig_radar.write_image(\"classification_radar_chart.png\", format=\"png\", scale=3)  # 300 DPI equivalent\n",
        "print(\"Saved classification radar chart to 'classification_radar_chart.png'\")\n",
        "\n",
        "# 3. Seaborn Heatmap for Classification Metrics\n",
        "plt.figure(figsize=(10, 6))\n",
        "class_heatmap_data = class_df.set_index('Model')[['Accuracy', 'Precision_0', 'Recall_0', 'F1_0',\n",
        "                                                 'Precision_1', 'Recall_1', 'F1_1']]\n",
        "sns.heatmap(class_heatmap_data, annot=True, cmap='YlGnBu', fmt=\".4f\", linewidths=0.5)\n",
        "plt.title(\"Classification Metrics Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"classification_heatmap.png\", dpi=300)\n",
        "plt.close()\n",
        "print(\"Saved classification heatmap to 'classification_heatmap.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puVYwM1x2zE5",
        "outputId": "e92a2d32-be3b-40b4-a3ae-50257425c77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved regression bar plot to 'regression_bar_plot.png'\n",
            "Saved regression heatmap to 'regression_heatmap.png'\n",
            "Saved classification bar plot to 'classification_bar_plot.png'\n",
            "Saved classification radar chart to 'classification_radar_chart.png'\n",
            "Saved classification heatmap to 'classification_heatmap.png'\n"
          ]
        }
      ]
    }
  ]
}